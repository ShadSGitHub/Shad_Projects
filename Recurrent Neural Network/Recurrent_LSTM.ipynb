{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LwvvMtG18SK"
   },
   "source": [
    "# Recurrent Neural Network Homework\n",
    "\n",
    "This is the 4th assignment for CAP 4630 and we will implement a basic RNN network and an LSTM network with Keras to solve two problems. \\\n",
    "You will use **\"Tasks\"** and **\"Hints\"** to finish the work. **(Total points 85, plus 15 bonus points)** \\\n",
    "You may use Machine Learning libaries like Scikit-learn for data preprocessing.\n",
    "\n",
    "**Task Overview:**\n",
    "- Implement a basic RNN network to solve time series prediction \n",
    "- Implement an LSTM network to conduct sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l24oSrIK18SL"
   },
   "source": [
    "## 1 - Implement Basic RNN network with Keras to predict time series##\n",
    "### 1.1 Prepare the data (17 Points)\n",
    "\n",
    "Prepare time series data for deep neural network training.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the given train and test data: \"train.txt\" and \"test.txt\". **(5 Points)**\n",
    "2. Generate the **TRAIN** and **TEST** labels. **(5 Points)**\n",
    "2. Normalize the **TRAIN** and **TEST** data with sklearn function \"MinMaxScaler\". **(5 Points)**\n",
    "3. Print out the **TEST** data and label. **(2 Points)**\n",
    "\n",
    "**Hints:**  \n",
    "1. The length of original train data is 113 which starts from **\"1949-01\"** to **\"1958-05\"**. The length of original test data is 29, which starts from **\"1958-07\"** to **\"1960-11\"**. \n",
    "2. Set the data types of both train and test data to \"float32\". \n",
    "3. When you prepared input data X (sequences) and oupt data Y (labels), please consider the following relationship:\n",
    "    - The sequence X should be the **past 12** datapoints in the time series, i.e., observation sequence with historical window of 12. You may check the time series data and think about the reason.\n",
    "    - The label Y should be the **next 1** datapoint in the time series (one point ahead prediction).\n",
    "4. The first 3 train data and label should be:\n",
    "\n",
    "trainX[0] = [[0.5801282 &nbsp; 0.625 &nbsp; 0.30128205 &nbsp;0.15705132 &nbsp;0. &nbsp; 0.08653843 &nbsp; 0.16025639 &nbsp; 0.1025641 &nbsp; 0.3076923 &nbsp; 0.27564108 &nbsp;0.3525641 &nbsp; 0.5192307]]\\\n",
    "trainY[0] = [0.7628205]\n",
    "\n",
    "trainX[1] = [[0.625   &nbsp;   0.30128205&nbsp; 0.15705132&nbsp; 0.   &nbsp;      0.08653843 &nbsp;0.16025639&nbsp; 0.1025641 &nbsp; 0. &nbsp;3076923&nbsp; 0.27564108 &nbsp;0.3525641&nbsp;  0.5192307&nbsp;  0.7628205 ]]\\\n",
    "trainY[1] = [0.798077]\n",
    "\n",
    "trainX[2] =  [[0.30128205 &nbsp; 0.15705132 &nbsp; 0.   &nbsp;   0.&nbsp; 08653843&nbsp;0.16025639&nbsp;0.1025641 &nbsp; 0.3076923 &nbsp;0.27564108 &nbsp;0.3525641 &nbsp; 0.5192307 &nbsp;0.7628205 &nbsp; 0.798077]]\\\n",
    "trainY[2] = [0.49038458]\n",
    "\n",
    "5. Apply the MinMaxScaler to both the train and test data.\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html\n",
    "\n",
    "\n",
    "6. After the preparation with scaler fitting, the shapes of trainX, trainY, testX, and testY are as follows:\\\n",
    "trainX.shape = (101, 1, 12)\\\n",
    "trainY.shape = (101,)\\\n",
    "testX.shape = (17, 1, 12)\\\n",
    "testY.shape = (17,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hS7xhrC3-_-1"
   },
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "### Set random seed to ensure deterministic results\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "reset_random_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "shAj2Y6IuxUv"
   },
   "outputs": [],
   "source": [
    "### Prepare and Preprocess Data Here ###\n",
    "\n",
    "from pandas import read_csv\n",
    "\n",
    "### Design a Function to Prepare Observation Sequences and Corresponding Labels ###\n",
    "\n",
    "# def create_dataset(dataset, look_back=12): # look_back is used to specify input sequence length\n",
    "#     dataX, dataY = [], []\n",
    "#     for i in range(len(dataset)-look_back):\n",
    "#         dataX.append( ) # make sure correct start and end elements\n",
    "#         dataY.append( ) # make sure correct start and end elements; here, we have only one point ahead for prediction\n",
    "#         return np.array(dataX), np.array(dataY)\n",
    "\n",
    "\n",
    "### Train and Test Data Loading with float32 type ####\n",
    "\n",
    "# dataframe_test = read_csv()\n",
    "# dataset_test = dataframe_test.values\n",
    "# dataset_test = dataset_test.astype('float32')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8MlgYTvvIeD"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "### Scale Training and Test Data to [0, 1] ###\n",
    "\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1)) # specify the scaler\n",
    "# train = scaler.fit_transform() # fit the scaler to the training data\n",
    "# test = scaler.fit_transform() # fit the scaler to the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and Test Data Split\n",
    "\n",
    "# trainX, trainY = create_dataset(.., look_back=12) # historical window is 12; future window is 1.\n",
    "# testX, testY = create_dataset(..., look_back=12)\n",
    "\n",
    "### Train and Test Data Reshape (to fit RNN input)\n",
    "\n",
    "# trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1])) \n",
    "# testX = np.reshape(testX, (...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AQ1uHWzX8wlH"
   },
   "outputs": [],
   "source": [
    "# print out the test data and label here\n",
    "\n",
    "# print(testX)\n",
    "# print(testY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0AlakqA_vuFb"
   },
   "source": [
    "### 1.2 - Build the RNN model (20 Points) ##\n",
    "\n",
    "\n",
    "Build an RNN model with SimpleRNN cell. \n",
    "\n",
    "**Tasks:**\n",
    "1. Build an RNN model with 1 RNN layer and 1 Dense layer.  **(10 Points)**\n",
    "2. Compile the model. **(5 Points)**\n",
    "3. Train the model for 100 epochs with **batch_size = 10**. **(5 Points)**\n",
    "\n",
    "**Hints:**  \n",
    "1. You may consider **tensorflow.keras.layers.SimpleRNN(unit_size=4)** to specify RNN cells.\n",
    "2. Use loss function = 'mean_squared_error' and select **Adam** optimizer with **learning_rate=0.01** and other default settings.\n",
    "3. After first epoch, the train loss is changed to around **0.0656**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jn92qh8oyq0B"
   },
   "outputs": [],
   "source": [
    "### Build the RNN Model ###\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "# model = Sequential() # Declare Sequential class and assign it to variable \"model\"\n",
    "# model.add(keras.layers.SimpleRNN( )) # Add a simple RNN layer with unit_size=4 in the model \n",
    "# model.add(keras.layers.Dense( )) # Add a following Dense layer with units=1 in the model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GnO-5WT-3hgH"
   },
   "outputs": [],
   "source": [
    "### Compile the RNN model ###\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "# model.compile(...) # model compiled with mean_squared_error loss and adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tpZAutlzify"
   },
   "outputs": [],
   "source": [
    "### Train the RNN model and PRINT OUT MODEL STRUCTURE with model.summary() ###\n",
    "\n",
    "# model.fit(...) # model fit with epoch=100, batch_size=10; verbose=2 is optional.\n",
    "# model.summary() # print out model structure with model.summary()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "id": "Dd2jZl4n0H8m"
   },
   "source": [
    "### 1.3 Evaluate Predictive Model Performance (10 Points)\n",
    "\n",
    "Predict datapoints with the observed datapoints and trained model. \n",
    "\n",
    "**Tasks:**\n",
    "1. Do direct prediction on train and test datapoints with the obtained model in section 1.2. **(2 Points)**\n",
    "2. Scale the prediction results back to original representation with the scaler. **(3 Points)**\n",
    "3. Calculate root mean squared error (RMSE) and **print out** the error for **both TRAIN and TEST**. **(3 Points)**\n",
    "4. **Plot** the **TEST** label and prediction. **(2 Points)**\n",
    "\n",
    "\n",
    "**Hints:**  \n",
    "1. Scale back the predictions with the build-in function \"scaler.inverse_transform\".\\\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler.inverse_transform\n",
    "2. For validation: Train Score: **~13 RMSE** Test Score: **~19 RMSE**\n",
    "3. The plot for validation is shown below (observation test data are blue and prediction results are orange):\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KNEkAMxnz8Mq"
   },
   "outputs": [],
   "source": [
    "### Make Predictions ###\n",
    "\n",
    "# trainPredict = model.predict( )\n",
    "# testPredict = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbnRqEv9z-he"
   },
   "outputs": [],
   "source": [
    "### Scale Back Predictions ###\n",
    "\n",
    "# trainPredict = scaler.inverse_transform(trainPredict) # scale train prediction back with scaler.inverse_transform()\n",
    "# trainY = scaler.inverse_transform([trainY])  # scale train labels back with scaler.inverse_transform()\n",
    "\n",
    "# testPredict = scaler.inverse_transform( ) # scale test prediction back with scaler.inverse_transform()\n",
    "# testY = scaler.inverse_transform( ) # scale test labels back with scaler.inverse_transform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xdBWzmE91G6_"
   },
   "outputs": [],
   "source": [
    "### Calculate Root Mean Squared Error (RMSE) ###\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error # Import mean_squared_error from sklearn.metrics\n",
    "\n",
    "# trainScore = math.sqrt(mean_squared_error(trainY[0], trainPredict[:,0])) \n",
    "# testScore = \n",
    "# print('Train Score: %.2f RMSE' % (trainScore))\n",
    "# print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txdu8q7l1aju"
   },
   "outputs": [],
   "source": [
    "### Plot Baseline and Predictions ###\n",
    "\n",
    "# plt.plot(testY[0]) \n",
    "# plt.plot(testPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O49Ug-FhtCg8"
   },
   "source": [
    "## 2 - Build an LSTM model to conduct sentiment analysis ##\n",
    "\n",
    "### 2.1 Prepare the data (13 Points) ###\n",
    "\n",
    "Prepare IMDB data for reccurent neural network training.\n",
    "\n",
    "**Tasks:**\n",
    "1. Load the data from IMDB review dataset and **print out** the lengths of sequences. **(3 Points)**\n",
    "2. Preprocess review data to meet the network input requirement by specifying **number of words=1000**, setting **the analysis length of the review = 100**, and **padding the input sequences**. **(10 Points)**\n",
    "\n",
    "**Hints:**  \n",
    "1. You may load the IMDB data with keras.datasets.imdb.load_data(num_words=max_features). Here. max_features is set to **1000**.\n",
    "2. You may use keras.preprocessing.sequence.pad_sequences(x_train, maxlen) to pad the input sequences and set maxlen to **100**.\n",
    "\n",
    "**Note:**\\\n",
    "We train the built LSTM-based model with ALL training data; the **validation set** (aka **development set**) is set with the **testing set** for model evaluation. This split is common in the application with limited sampled observation data, like NLP problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UI4ki461S2V3"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "### Set random seed to ensure deterministic results\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvV1Sv2a18SM"
   },
   "outputs": [],
   "source": [
    "# Prepare the data here\n",
    "\n",
    "# max_features =  # Only consider the top 1k words\n",
    "# maxlen =  # Only consider the first 100 words of each movie review\n",
    "\n",
    "# (x_train, y_train), (x_val, y_val) = keras.datasets.imdb.load_data( ) # load IMDB data with specified num_words = 1000; testing set is set to validation set.\n",
    "# print(len(x_train), \"Training sequences\")\n",
    "# print(len(x_val), \"Validation sequences\")\n",
    "# x_train = keras.preprocessing.sequence.pad_sequences( ) # Pad IMDB training data with specified maxlen=100\n",
    "# x_val = keras.preprocessing.sequence.pad_sequences( ) # Pad IMDB validation data with specified maxlen=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_JFQeWK18SR"
   },
   "source": [
    "### 2.2 - Design and train LSTM model (25 Points) ###\n",
    "\n",
    "Build an LSTM model.\n",
    "\n",
    "**Tasks:**\n",
    "1. Build the LSTM model with **1 embedding layer**, **1 LSTM layer**, and **1 Dense layer**. **Print out** model summary. The embedding vector is specified with the dimension of **8**. **(10 Points)**\n",
    "2. Compile the LSTM model with **Adam** optimizer, **binary_crossentropy** loss function, and **accuracy** metrics. **(5 Points)**  \n",
    "3. Train the LSTM model with **batch_size=64 for 10 epochs** and report **training and validation accuracies over epochs**. **(5 Points)**\n",
    "4. **Print out** best validation accuracy. **(5 Points)**\n",
    "\n",
    "\n",
    "\n",
    "**Hints:**  \n",
    "1. Set input dimension to **1000** and output dimension to **8** for embedding layer.\n",
    "2. Set **unit_size=8** for LSTM layer.\n",
    "3. Set activation function to **sigmoid** for Dense layer.\n",
    "4. For validation: the outputs for first epoch should be close to（but maybe not exactly following） the statistics below:\\\n",
    "**loss: ~0.5675 - accuracy: ~0.7072 - val_loss: ~0.4549 - val_accuracy: ~0.8020**\n",
    "\n",
    "**Useful Reference:**\n",
    "1. https://keras.io/examples/nlp/bidirectional_lstm_imdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UDqqgFt118SS"
   },
   "outputs": [],
   "source": [
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in an 8-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 8 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model with model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vqvy2tdEw7J"
   },
   "source": [
    "### 2.3 - LSTM hyperparameter tuning (Bonus 15 Points) ###\n",
    "\n",
    "Boost the performance of obtained LSTM (aka vanilla model) by hyperparameter tuning.\n",
    "\n",
    "**Tasks:**\n",
    "- All modificiations are directly conducted based on the vanilla model above (from 2.2).\n",
    "- For each scenario, **report <span style=\"color:red\"> BEST Validation Accuracy </span> and generate Training/Validation <span style=\"color:red\"> Accuracy plots over epochs</span>**. You may just paste the plot figures in the cells with **Markdown mode**. Make sure it is correctly shown after jupyter notebook run the cell.\n",
    "1.  Scenario 1 (**5 points**):\n",
    "    - Add one additional LSTM layer (totally 2 LSTM layers).\n",
    "    - Modify the embedding dimension to 16.\n",
    "    - Modify the units of LSTM to 16.\n",
    "2. Scenario 2 (**5 points**)\n",
    "    - Add one additional LSTM layer (totally 2 LSTM layers).\n",
    "    - Modify the embedding dimension to 128.\n",
    "    - Modify the units of LSTM to 128.\n",
    "3. Scenario 3 (**5 points**)\n",
    "    - Add one additional LSTM layer (totally 2 LSTM layers).\n",
    "    - Modify the embedding dimension to 128.\n",
    "    - Modify the units of LSTM to 128.\n",
    "    - Increase analysis length for review data to maxlen = 200\n",
    "\n",
    "**Hints:**  \n",
    "For validation: the outputs for first epoch should be close to（but maybe not exactly following） the statistics below:\n",
    "- Scenario 1: **loss: ~0.4968 - accuracy: ~0.7450 - val_loss: ~0.4079 - val_accuracy: ~0.8198**\n",
    "- Scenario 2: **loss: ~0.4764 - accuracy: ~0.7670 - val_loss: ~0.4133 - val_accuracy: ~0.8179**\n",
    "- Scenario 3: **loss: ~0.4819 - accuracy: ~0.7644 - val_loss: ~0.4031 - val_accuracy: ~0.8105**\n",
    "\n",
    "You may follow the example from the reference below to add additional LSTM layer.\n",
    "\n",
    "**Useful Reference:**\n",
    "1. https://keras.io/examples/nlp/bidirectional_lstm_imdb/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Keod5xXkEKnx"
   },
   "outputs": [],
   "source": [
    "########################### Scenario 1 ###########################\n",
    "##################################################################\n",
    "\n",
    "### Set random seed to ensure deterministic results ###\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data\n",
    "\n",
    "# max_features =  # Only consider the top 1k words\n",
    "# maxlen =  # Only consider the first 100 words of each movie review\n",
    "\n",
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in a 16-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 16 hidden states (aka units); set return_sequences=true.\n",
    "# x = layers.LSTM( )(x) # Add 2nd layer of LSTM with 16 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Scenario 2 ###########################\n",
    "##################################################################\n",
    "\n",
    "### Set random seed to ensure deterministic results ###\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data\n",
    "\n",
    "# max_features =   # Only consider the top 1k words\n",
    "# maxlen =  # Only consider the first 100 words of each movie review\n",
    "\n",
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in a 128-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 128 hidden states (aka units); set return_sequences=true.\n",
    "# x = layers.LSTM( )(x) # Add 2nd layer of LSTM with 128 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Scenario 3 ###########################\n",
    "##################################################################\n",
    "\n",
    "### Set random seed to ensure deterministic results ###\n",
    "import os\n",
    "seed_value = 1\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "def reset_random_seeds():\n",
    "   tf.random.set_seed(seed_value)\n",
    "   np.random.seed(seed_value)\n",
    "   random.seed(seed_value)\n",
    "\n",
    "reset_random_seeds() # randomly set initial data\n",
    "\n",
    "max_features =   # Only consider the top 1k words\n",
    "maxlen = # Only consider the first 200 words of each movie review\n",
    "\n",
    "### Model design with Embedding and LSTM layers ####\n",
    "# inputs = keras.Input(shape=(None,), dtype=\"int32\") # This is an easy way to set an adaptive length for input sequence\n",
    "# x = layers.Embedding( )(inputs) # Embed data in a 128-dimensional vector\n",
    "# x = layers.LSTM( )(x) # Add 1st layer of LSTM with 128 hidden states (aka units); set return_sequences=true.\n",
    "# x = layers.LSTM( )(x) # Add 2nd layer of LSTM with 128 hidden states (aka units)\n",
    "# outputs = layers.Dense( )(x) # Add a classifier with units=1 and activation=\"sigmoid\"\n",
    "\n",
    "### Clear cached model to refresh memory and build new model for training ###\n",
    "keras.backend.clear_session() # Clear cached model\n",
    "# model = keras.Model(inputs, outputs) # Build new keras model\n",
    "# model.summary() # Print out model summary\n",
    "\n",
    "# model.compile( ) # Compile built model with \"adam\", \"binary_crossentropy\", and metrics=[\"accuracy\"]\n",
    "# model.fit( ) # Train the compiled model using model.fit() with batch_size=64, epochs=10, and validation_data=(x_val, y_val)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Homework_04.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "neural-networks-deep-learning",
   "graded_item_id": "XaIWT",
   "launcher_item_id": "zAgPl"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
